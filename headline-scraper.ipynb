{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV File\n",
    "\n",
    "We first need to read the .csv file that is in the current directly. The `keep_default_na=False` argument will prevent Pandas from putting NaN data in empty cells.\n",
    "\n",
    "Once you've loaded the .csv data in an variable, you can run `.head()` method to peek at the first five rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>newslink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6290375</td>\n",
       "      <td>http://archive.redding.com/news/ex-chp-officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7187899</td>\n",
       "      <td>http://archive.signalscv.com/archives/150962/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6646879</td>\n",
       "      <td>http://archive.vcstar.com/news/guilty-officer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6993951</td>\n",
       "      <td>http://archive.vcstar.com/news/local/sheriffs-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1335727</td>\n",
       "      <td>http://archive.vcstar.com/news/sheriffs-deputy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           newslink\n",
       "0  6290375  http://archive.redding.com/news/ex-chp-officer...\n",
       "1  7187899      http://archive.signalscv.com/archives/150962/\n",
       "2  6646879  http://archive.vcstar.com/news/guilty-officer-...\n",
       "3  6993951  http://archive.vcstar.com/news/local/sheriffs-...\n",
       "4  1335727  http://archive.vcstar.com/news/sheriffs-deputy..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "mycsv = pd.read_csv(\"news-links-with-id.csv\", keep_default_na=False)\n",
    "mycsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column\n",
    "\n",
    "To create a column with Pandas, simply assign a value to the property of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>newslink</th>\n",
       "      <th>news_headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6290375</td>\n",
       "      <td>http://archive.redding.com/news/ex-chp-officer...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7187899</td>\n",
       "      <td>http://archive.signalscv.com/archives/150962/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6646879</td>\n",
       "      <td>http://archive.vcstar.com/news/guilty-officer-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6993951</td>\n",
       "      <td>http://archive.vcstar.com/news/local/sheriffs-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1335727</td>\n",
       "      <td>http://archive.vcstar.com/news/sheriffs-deputy...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           newslink news_headlines\n",
       "0  6290375  http://archive.redding.com/news/ex-chp-officer...               \n",
       "1  7187899      http://archive.signalscv.com/archives/150962/               \n",
       "2  6646879  http://archive.vcstar.com/news/guilty-officer-...               \n",
       "3  6993951  http://archive.vcstar.com/news/local/sheriffs-...               \n",
       "4  1335727  http://archive.vcstar.com/news/sheriffs-deputy...               "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycsv[\"news_headlines\"] = \"\"\n",
    "mycsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set headers\n",
    "\n",
    "When scraping websites, you should spoof your header and referer. This prevents the website from thinkinking you're a spammer. Of course, this isn't a foolproof measure, and most websites will block you if you access them too many times in a row (which is a good thing). This header spoof only really helps from very paranoid websites that block all requests from unknown referers. You can change this to a URL you control. Note that the recipient website you're scraping can see the referer in their server logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "'referer': 'https://example.com',\n",
    "'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through headlines to fetch HTML\n",
    "\n",
    "This will go through each headline using a for loop. Study the code block first, and then come back here. We'll describe each setp of the loop.\n",
    "\n",
    "```\n",
    "for index, row in mycsv.iterrows():\n",
    "```\n",
    "\n",
    "`index` is a counter. It starts from 0, and increments each time the loop runs. We will use the index variable later to insert the retrieved headline back into the table at the appropriate row. Just remember, the index refers to which row we're on.\n",
    "\n",
    "`row` will be a reference to the data in each row in the spreadsheet. So, row['column_name'] could retrive a particular cell. Every time the loop runs, the row variable will refer to data in the next row.\n",
    "\n",
    "`mycsv.iterrows()` refers to all of the rows in the table, and it's just a way for us to cycle through all of them.\n",
    "\n",
    "```\n",
    "url = row['newslink'].strip()\n",
    "```\n",
    "\n",
    "Once in the loop, we will extract data from the `newlink` column. We will extract the specific cell with a URL in it. The `strip()` removes leading/trailing whitespace.\n",
    "\n",
    "```\n",
    "try: \n",
    "    webpage = requests.get(url, headers = headers, timeout = 4)\n",
    "    webpage.encoding = 'utf-8'\n",
    "```\n",
    "\n",
    "The try command sets up a mechanism to catch errors, while allowing the loop to continue (so it doesn't break every time a website is unresponsive). The `except` creates an exception without breaking the loop. So as it's running, we'll see messages occasionally from websites that failed to give us a headline.\n",
    "\n",
    "We'll use the requests library to fetch the webpage, supplying the headers variable, and specifying how many seconds to wait before giving up and moving on to the next website.\n",
    "\n",
    "```\n",
    "soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "```\n",
    "\n",
    "We'll use BeautifulSoup to parse the result from fetching the webpage. BeautifulSoup can parse several different types of files. We're using the html parser to interpret html.\n",
    "\n",
    "```\n",
    "title = soup.find('meta', {'property': 'og:title'})\n",
    "```\n",
    "\n",
    "This finds the `<meta content=\"some headline\" property=\"og:title\">` tag in the webpage, which most news sites have as part of their SEO and to supply social networks with information about their articles.\n",
    "\n",
    "```\n",
    "if title is not None:\n",
    "    mycsv.iat[index, mycsv.columns.get_loc(\"news_headlines\")] = title['content']\n",
    "sleep(0.1)\n",
    "```\n",
    "\n",
    "The if statement makes sure we were able to find a title. The `.iat` is a Pandas command that will allow us to insert a cell at a specific location, getting the location of the correct column, and assigning it the title we found.\n",
    "\n",
    "The sleep command slows things down, so we don't make too many requests at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test things out before running the loop. Un-comment the code below to run for just one headline.\n",
    "# url = mycsv['newslink'][0]\n",
    "# webpage = requests.get(url, headers=headers,timeout=4)\n",
    "# webpage.encoding = 'utf-8'\n",
    "# soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "# title = soup.find('meta', {'property': 'og:title'})\n",
    "# title['content']\n",
    "\n",
    "\n",
    "for index, row in mycsv.iterrows():\n",
    "    url = row['newslink'].strip()\n",
    "    try:\n",
    "        webpage = requests.get(url, headers=headers,timeout=4)\n",
    "        webpage.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "        title = soup.find('meta', {'property': 'og:title'})\n",
    "        if title is not None:\n",
    "            mycsv.iat[index, mycsv.columns.get_loc(\"news_headlines\")] = title['content']\n",
    "        sleep(0.1)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"timeout occured\")\n",
    "mycsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CSV file of the output\n",
    "\n",
    "The following command will save a .csv file of our mycsv data, with the additional column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv.to_csv(\"data-with-headlines.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
